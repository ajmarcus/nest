Nest
======

A demo of hive's capabilities.

### Configuration ###

Put the following variables in your kettle.properties file:
LAPPY_AWS_PUB_KEY=[PUBLIC KEY]
LAPPY_AWS_PRV_KEY=[PRIVATE KEY]

### Sample EMR cli commands ###

1. List active jobflows
```bash
./elastic-mapreduce --list --active
```

2. SSH to master node of jobflow
```bash
./elastic-mapreduce --ssh [JOBFLOW_ID]
```

3. SSH to master node and forward JobTracker port
```bash
ssh -i /path/to/keyfile.pem -L 9100:localhost:9100 -l hadoop [HOSTNAME]
```

3. Add spot instances to running jobflow
```bash
./elastic-mapreduce -j [JOBFLOW_ID] \
    --add-instance-group task \
    --instance-type m1.xlarge \
    --instance-count 3 \
    --bid-price 0.60
```

For a handy utility with the EMR cli see Chris Wensel's [bash-emr|https://github.com/cwensel/bash-emr].

### Issues ###

1. PDI uses Hive 0.7

2. PDI does not fail gracefully when JobFlow fails

INFO  15-01 23:05:50,722 - Load Nest - Load Nest (Job Flow ID: j-YNLJ03A8TRA8) execution status: FAILED
INFO  15-01 23:05:50,723 - Sending Request: GET https://nest.hive.s3.amazonaws.com /j-YNLJ03A8TRA8%2Fsteps%2F1%2Fstdout Headers: (Authorization: AWS AKIAIVB34PATGG5YCTSA:oWTPFNKuJshfb99VYZ0/XCNBAnA=, Date: Wed, 16 Jan 2013 04:05:50 GMT, Content-Type: application/x-www-form-urlencoded; charset=utf-8, ) 
INFO  15-01 23:05:51,013 - Received error response: Status Code: 404, AWS Request ID: C09F4AE47071956B, AWS Error Code: NoSuchKey, AWS Error Message: The specified key does not exist., S3 Extended Request ID: zOvaQ2ItbYcsI8qV/1UKbBtUzkNFyi3j3+IyJ8y0R32HcZDDsc0ECsrrA2tBsfyL
ERROR 15-01 23:05:51,014 - Load Nest - The specified key does not exist.
ERROR 15-01 23:05:51,014 - Load Nest - Status Code: 404, AWS Request ID: C09F4AE47071956B, AWS Error Code: NoSuchKey, AWS Error Message: The specified key does not exist., S3 Extended Request ID: zOvaQ2ItbYcsI8qV/1UKbBtUzkNFyi3j3+IyJ8y0R32HcZDDsc0ECsrrA2tBsfyL
  at com.amazonaws.http.HttpClient.handleErrorResponse(HttpClient.java:472)
  at com.amazonaws.http.HttpClient.execute(HttpClient.java:195)
  at com.amazonaws.services.s3.AmazonS3Client.getObject(AmazonS3Client.java:724)
  at com.amazonaws.services.s3.AmazonS3Client.getObject(AmazonS3Client.java:637)
  at org.pentaho.amazon.hive.job.AmazonHiveJobExecutor.execute(AmazonHiveJobExecutor.java:266)
  at org.pentaho.di.job.Job.execute(Job.java:589)
  at org.pentaho.di.job.Job.execute(Job.java:728)
  at org.pentaho.di.job.Job.execute(Job.java:443)
  at org.pentaho.di.job.Job.run(Job.java:363)
